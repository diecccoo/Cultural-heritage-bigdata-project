:: loading settings :: url = jar:file:/opt/bitnami/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /root/.ivy2/cache
The jars for the packages stored in: /root/.ivy2/jars
org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-69648223-fc8c-4d1d-96b3-126789978990;1.0
	confs: [default]
	found org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0 in central
	found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0 in central
	found org.apache.kafka#kafka-clients;3.4.1 in central
	found org.lz4#lz4-java;1.8.0 in central
	found org.xerial.snappy#snappy-java;1.1.10.3 in central
	found org.slf4j#slf4j-api;2.0.7 in central
	found org.apache.hadoop#hadoop-client-runtime;3.3.4 in central
	found org.apache.hadoop#hadoop-client-api;3.3.4 in central
	found commons-logging#commons-logging;1.1.3 in central
	found com.google.code.findbugs#jsr305;3.0.0 in central
	found org.apache.commons#commons-pool2;2.11.1 in central
downloading https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/3.5.0/spark-sql-kafka-0-10_2.12-3.5.0.jar ...
	[SUCCESSFUL ] org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0!spark-sql-kafka-0-10_2.12.jar (576ms)
downloading https://repo1.maven.org/maven2/org/apache/spark/spark-token-provider-kafka-0-10_2.12/3.5.0/spark-token-provider-kafka-0-10_2.12-3.5.0.jar ...
	[SUCCESSFUL ] org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0!spark-token-provider-kafka-0-10_2.12.jar (180ms)
downloading https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/3.4.1/kafka-clients-3.4.1.jar ...
	[SUCCESSFUL ] org.apache.kafka#kafka-clients;3.4.1!kafka-clients.jar (1856ms)
downloading https://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar ...
	[SUCCESSFUL ] com.google.code.findbugs#jsr305;3.0.0!jsr305.jar (152ms)
downloading https://repo1.maven.org/maven2/org/apache/commons/commons-pool2/2.11.1/commons-pool2-2.11.1.jar ...
	[SUCCESSFUL ] org.apache.commons#commons-pool2;2.11.1!commons-pool2.jar (211ms)
downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-client-runtime/3.3.4/hadoop-client-runtime-3.3.4.jar ...
	[SUCCESSFUL ] org.apache.hadoop#hadoop-client-runtime;3.3.4!hadoop-client-runtime.jar (7712ms)
downloading https://repo1.maven.org/maven2/org/lz4/lz4-java/1.8.0/lz4-java-1.8.0.jar ...
	[SUCCESSFUL ] org.lz4#lz4-java;1.8.0!lz4-java.jar (163ms)
downloading https://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.1.10.3/snappy-java-1.1.10.3.jar ...
	[SUCCESSFUL ] org.xerial.snappy#snappy-java;1.1.10.3!snappy-java.jar(bundle) (387ms)
downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/2.0.7/slf4j-api-2.0.7.jar ...
	[SUCCESSFUL ] org.slf4j#slf4j-api;2.0.7!slf4j-api.jar (75ms)
downloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-client-api/3.3.4/hadoop-client-api-3.3.4.jar ...
	[SUCCESSFUL ] org.apache.hadoop#hadoop-client-api;3.3.4!hadoop-client-api.jar (3169ms)
downloading https://repo1.maven.org/maven2/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar ...
	[SUCCESSFUL ] commons-logging#commons-logging;1.1.3!commons-logging.jar (66ms)
:: resolution report :: resolve 76457ms :: artifacts dl 14620ms
	:: modules in use:
	com.google.code.findbugs#jsr305;3.0.0 from central in [default]
	commons-logging#commons-logging;1.1.3 from central in [default]
	org.apache.commons#commons-pool2;2.11.1 from central in [default]
	org.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]
	org.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]
	org.apache.kafka#kafka-clients;3.4.1 from central in [default]
	org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0 from central in [default]
	org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0 from central in [default]
	org.lz4#lz4-java;1.8.0 from central in [default]
	org.slf4j#slf4j-api;2.0.7 from central in [default]
	org.xerial.snappy#snappy-java;1.1.10.3 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   11  |   11  |   11  |   0   ||   11  |   11  |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-69648223-fc8c-4d1d-96b3-126789978990
	confs: [default]
	11 artifacts copied, 0 already retrieved (56767kB/1176ms)
25/05/14 11:51:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/05/14 11:51:22 INFO SparkContext: Running Spark version 3.5.5
25/05/14 11:51:22 INFO SparkContext: OS info Linux, 5.15.167.4-microsoft-standard-WSL2, amd64
25/05/14 11:51:22 INFO SparkContext: Java version 17.0.15
25/05/14 11:51:22 INFO ResourceUtils: ==============================================================
25/05/14 11:51:22 INFO ResourceUtils: No custom resources configured for spark.driver.
25/05/14 11:51:22 INFO ResourceUtils: ==============================================================
25/05/14 11:51:22 INFO SparkContext: Submitted application: ScannerConsumer
25/05/14 11:51:22 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/05/14 11:51:22 INFO ResourceProfile: Limiting resource is cpu
25/05/14 11:51:22 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/05/14 11:51:22 INFO SecurityManager: Changing view acls to: root,spark
25/05/14 11:51:22 INFO SecurityManager: Changing modify acls to: root,spark
25/05/14 11:51:22 INFO SecurityManager: Changing view acls groups to: 
25/05/14 11:51:22 INFO SecurityManager: Changing modify acls groups to: 
25/05/14 11:51:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root, spark; groups with view permissions: EMPTY; users with modify permissions: root, spark; groups with modify permissions: EMPTY
25/05/14 11:51:23 INFO Utils: Successfully started service 'sparkDriver' on port 36289.
25/05/14 11:51:24 INFO SparkEnv: Registering MapOutputTracker
25/05/14 11:51:24 INFO SparkEnv: Registering BlockManagerMaster
25/05/14 11:51:24 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/05/14 11:51:24 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/05/14 11:51:24 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/05/14 11:51:24 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2d7f3523-d16c-40c9-a7e3-b0a091d62f19
25/05/14 11:51:24 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
25/05/14 11:51:24 INFO SparkEnv: Registering OutputCommitCoordinator
25/05/14 11:51:25 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
25/05/14 11:51:26 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/05/14 11:51:26 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar at spark://b855e321a1ed:36289/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar with timestamp 1747223482229
25/05/14 11:51:26 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar at spark://b855e321a1ed:36289/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar with timestamp 1747223482229
25/05/14 11:51:26 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar at spark://b855e321a1ed:36289/jars/org.apache.kafka_kafka-clients-3.4.1.jar with timestamp 1747223482229
25/05/14 11:51:26 INFO SparkContext: Added JAR file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://b855e321a1ed:36289/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1747223482229
25/05/14 11:51:26 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar at spark://b855e321a1ed:36289/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1747223482229
25/05/14 11:51:26 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar at spark://b855e321a1ed:36289/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1747223482229
25/05/14 11:51:26 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar at spark://b855e321a1ed:36289/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1747223482229
25/05/14 11:51:26 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar at spark://b855e321a1ed:36289/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1747223482229
25/05/14 11:51:26 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar at spark://b855e321a1ed:36289/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1747223482229
25/05/14 11:51:26 INFO SparkContext: Added JAR file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar at spark://b855e321a1ed:36289/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1747223482229
25/05/14 11:51:26 INFO SparkContext: Added JAR file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://b855e321a1ed:36289/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1747223482229
25/05/14 11:51:26 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar at file:///root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar with timestamp 1747223482229
25/05/14 11:51:26 INFO Utils: Copying /root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar
25/05/14 11:51:26 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar at file:///root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar with timestamp 1747223482229
25/05/14 11:51:26 INFO Utils: Copying /root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar
25/05/14 11:51:26 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar at file:///root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar with timestamp 1747223482229
25/05/14 11:51:26 INFO Utils: Copying /root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.apache.kafka_kafka-clients-3.4.1.jar
25/05/14 11:51:27 INFO SparkContext: Added file file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1747223482229
25/05/14 11:51:27 INFO Utils: Copying /root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/com.google.code.findbugs_jsr305-3.0.0.jar
25/05/14 11:51:27 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar at file:///root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1747223482229
25/05/14 11:51:27 INFO Utils: Copying /root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.apache.commons_commons-pool2-2.11.1.jar
25/05/14 11:51:27 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar at file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1747223482229
25/05/14 11:51:27 INFO Utils: Copying /root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar
25/05/14 11:51:28 INFO SparkContext: Added file file:///root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar at file:///root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1747223482229
25/05/14 11:51:28 INFO Utils: Copying /root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.lz4_lz4-java-1.8.0.jar
25/05/14 11:51:28 INFO SparkContext: Added file file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar at file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1747223482229
25/05/14 11:51:28 INFO Utils: Copying /root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.xerial.snappy_snappy-java-1.1.10.3.jar
25/05/14 11:51:28 INFO SparkContext: Added file file:///root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar at file:///root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1747223482229
25/05/14 11:51:28 INFO Utils: Copying /root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.slf4j_slf4j-api-2.0.7.jar
25/05/14 11:51:28 INFO SparkContext: Added file file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar at file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1747223482229
25/05/14 11:51:28 INFO Utils: Copying /root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.apache.hadoop_hadoop-client-api-3.3.4.jar
25/05/14 11:51:28 INFO SparkContext: Added file file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1747223482229
25/05/14 11:51:28 INFO Utils: Copying /root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/commons-logging_commons-logging-1.1.3.jar
25/05/14 11:51:28 INFO Executor: Starting executor ID driver on host b855e321a1ed
25/05/14 11:51:29 INFO Executor: OS info Linux, 5.15.167.4-microsoft-standard-WSL2, amd64
25/05/14 11:51:29 INFO Executor: Java version 17.0.15
25/05/14 11:51:29 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/05/14 11:51:29 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@3fd8dd0f for default.
25/05/14 11:51:29 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar with timestamp 1747223482229
25/05/14 11:51:29 INFO Utils: /root/.ivy2/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar has been previously copied to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar
25/05/14 11:51:29 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1747223482229
25/05/14 11:51:29 INFO Utils: /root/.ivy2/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar has been previously copied to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.apache.hadoop_hadoop-client-api-3.3.4.jar
25/05/14 11:51:29 INFO Executor: Fetching file:///root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1747223482229
25/05/14 11:51:29 INFO Utils: /root/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar has been previously copied to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/com.google.code.findbugs_jsr305-3.0.0.jar
25/05/14 11:51:29 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1747223482229
25/05/14 11:51:29 INFO Utils: /root/.ivy2/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar has been previously copied to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar
25/05/14 11:51:29 INFO Executor: Fetching file:///root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1747223482229
25/05/14 11:51:29 INFO Utils: /root/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar has been previously copied to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.xerial.snappy_snappy-java-1.1.10.3.jar
25/05/14 11:51:29 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar with timestamp 1747223482229
25/05/14 11:51:29 INFO Utils: /root/.ivy2/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar has been previously copied to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar
25/05/14 11:51:29 INFO Executor: Fetching file:///root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1747223482229
25/05/14 11:51:29 INFO Utils: /root/.ivy2/jars/org.slf4j_slf4j-api-2.0.7.jar has been previously copied to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.slf4j_slf4j-api-2.0.7.jar
25/05/14 11:51:29 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1747223482229
25/05/14 11:51:29 INFO Utils: /root/.ivy2/jars/org.apache.commons_commons-pool2-2.11.1.jar has been previously copied to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.apache.commons_commons-pool2-2.11.1.jar
25/05/14 11:51:29 INFO Executor: Fetching file:///root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1747223482229
25/05/14 11:51:29 INFO Utils: /root/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar has been previously copied to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/commons-logging_commons-logging-1.1.3.jar
25/05/14 11:51:29 INFO Executor: Fetching file:///root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1747223482229
25/05/14 11:51:29 INFO Utils: /root/.ivy2/jars/org.lz4_lz4-java-1.8.0.jar has been previously copied to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.lz4_lz4-java-1.8.0.jar
25/05/14 11:51:29 INFO Executor: Fetching file:///root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar with timestamp 1747223482229
25/05/14 11:51:29 INFO Utils: /root/.ivy2/jars/org.apache.kafka_kafka-clients-3.4.1.jar has been previously copied to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.apache.kafka_kafka-clients-3.4.1.jar
25/05/14 11:51:29 INFO Executor: Fetching spark://b855e321a1ed:36289/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1747223482229
25/05/14 11:51:29 INFO TransportClientFactory: Successfully created connection to b855e321a1ed/172.18.0.4:36289 after 129 ms (0 ms spent in bootstraps)
25/05/14 11:51:29 INFO Utils: Fetching spark://b855e321a1ed:36289/jars/commons-logging_commons-logging-1.1.3.jar to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/fetchFileTemp4049489081825586214.tmp
25/05/14 11:51:29 INFO Utils: /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/fetchFileTemp4049489081825586214.tmp has been previously copied to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/commons-logging_commons-logging-1.1.3.jar
25/05/14 11:51:29 INFO Executor: Adding file:/tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/commons-logging_commons-logging-1.1.3.jar to class loader default
25/05/14 11:51:29 INFO Executor: Fetching spark://b855e321a1ed:36289/jars/org.slf4j_slf4j-api-2.0.7.jar with timestamp 1747223482229
25/05/14 11:51:29 INFO Utils: Fetching spark://b855e321a1ed:36289/jars/org.slf4j_slf4j-api-2.0.7.jar to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/fetchFileTemp10747112586739713309.tmp
25/05/14 11:51:29 INFO Utils: /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/fetchFileTemp10747112586739713309.tmp has been previously copied to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.slf4j_slf4j-api-2.0.7.jar
25/05/14 11:51:29 INFO Executor: Adding file:/tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.slf4j_slf4j-api-2.0.7.jar to class loader default
25/05/14 11:51:29 INFO Executor: Fetching spark://b855e321a1ed:36289/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1747223482229
25/05/14 11:51:29 INFO Utils: Fetching spark://b855e321a1ed:36289/jars/com.google.code.findbugs_jsr305-3.0.0.jar to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/fetchFileTemp13849162351454799360.tmp
25/05/14 11:51:29 INFO Utils: /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/fetchFileTemp13849162351454799360.tmp has been previously copied to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/com.google.code.findbugs_jsr305-3.0.0.jar
25/05/14 11:51:29 INFO Executor: Adding file:/tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/com.google.code.findbugs_jsr305-3.0.0.jar to class loader default
25/05/14 11:51:29 INFO Executor: Fetching spark://b855e321a1ed:36289/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar with timestamp 1747223482229
25/05/14 11:51:29 INFO Utils: Fetching spark://b855e321a1ed:36289/jars/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/fetchFileTemp17244520466646533631.tmp
25/05/14 11:51:29 INFO Utils: /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/fetchFileTemp17244520466646533631.tmp has been previously copied to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar
25/05/14 11:51:29 INFO Executor: Adding file:/tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.apache.spark_spark-token-provider-kafka-0-10_2.12-3.5.0.jar to class loader default
25/05/14 11:51:29 INFO Executor: Fetching spark://b855e321a1ed:36289/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar with timestamp 1747223482229
25/05/14 11:51:29 INFO Utils: Fetching spark://b855e321a1ed:36289/jars/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/fetchFileTemp4919599220914931363.tmp
25/05/14 11:51:30 INFO Utils: /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/fetchFileTemp4919599220914931363.tmp has been previously copied to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar
25/05/14 11:51:30 INFO Executor: Adding file:/tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.apache.spark_spark-sql-kafka-0-10_2.12-3.5.0.jar to class loader default
25/05/14 11:51:30 INFO Executor: Fetching spark://b855e321a1ed:36289/jars/org.lz4_lz4-java-1.8.0.jar with timestamp 1747223482229
25/05/14 11:51:30 INFO Utils: Fetching spark://b855e321a1ed:36289/jars/org.lz4_lz4-java-1.8.0.jar to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/fetchFileTemp15600700846969981170.tmp
25/05/14 11:51:30 INFO Utils: /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/fetchFileTemp15600700846969981170.tmp has been previously copied to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.lz4_lz4-java-1.8.0.jar
25/05/14 11:51:30 INFO Executor: Adding file:/tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.lz4_lz4-java-1.8.0.jar to class loader default
25/05/14 11:51:30 INFO Executor: Fetching spark://b855e321a1ed:36289/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar with timestamp 1747223482229
25/05/14 11:51:30 INFO Utils: Fetching spark://b855e321a1ed:36289/jars/org.xerial.snappy_snappy-java-1.1.10.3.jar to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/fetchFileTemp569136478955000989.tmp
25/05/14 11:51:30 INFO Utils: /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/fetchFileTemp569136478955000989.tmp has been previously copied to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.xerial.snappy_snappy-java-1.1.10.3.jar
25/05/14 11:51:30 INFO Executor: Adding file:/tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.xerial.snappy_snappy-java-1.1.10.3.jar to class loader default
25/05/14 11:51:30 INFO Executor: Fetching spark://b855e321a1ed:36289/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar with timestamp 1747223482229
25/05/14 11:51:30 INFO Utils: Fetching spark://b855e321a1ed:36289/jars/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/fetchFileTemp7016198486947711401.tmp
25/05/14 11:51:30 INFO Utils: /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/fetchFileTemp7016198486947711401.tmp has been previously copied to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar
25/05/14 11:51:30 INFO Executor: Adding file:/tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.apache.hadoop_hadoop-client-runtime-3.3.4.jar to class loader default
25/05/14 11:51:30 INFO Executor: Fetching spark://b855e321a1ed:36289/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar with timestamp 1747223482229
25/05/14 11:51:30 INFO Utils: Fetching spark://b855e321a1ed:36289/jars/org.apache.hadoop_hadoop-client-api-3.3.4.jar to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/fetchFileTemp16958793162543642248.tmp
25/05/14 11:51:31 INFO Utils: /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/fetchFileTemp16958793162543642248.tmp has been previously copied to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.apache.hadoop_hadoop-client-api-3.3.4.jar
25/05/14 11:51:31 INFO Executor: Adding file:/tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.apache.hadoop_hadoop-client-api-3.3.4.jar to class loader default
25/05/14 11:51:31 INFO Executor: Fetching spark://b855e321a1ed:36289/jars/org.apache.kafka_kafka-clients-3.4.1.jar with timestamp 1747223482229
25/05/14 11:51:31 INFO Utils: Fetching spark://b855e321a1ed:36289/jars/org.apache.kafka_kafka-clients-3.4.1.jar to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/fetchFileTemp18011782626727815022.tmp
25/05/14 11:51:31 INFO Utils: /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/fetchFileTemp18011782626727815022.tmp has been previously copied to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.apache.kafka_kafka-clients-3.4.1.jar
25/05/14 11:51:31 INFO Executor: Adding file:/tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.apache.kafka_kafka-clients-3.4.1.jar to class loader default
25/05/14 11:51:31 INFO Executor: Fetching spark://b855e321a1ed:36289/jars/org.apache.commons_commons-pool2-2.11.1.jar with timestamp 1747223482229
25/05/14 11:51:31 INFO Utils: Fetching spark://b855e321a1ed:36289/jars/org.apache.commons_commons-pool2-2.11.1.jar to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/fetchFileTemp89009104113542187.tmp
25/05/14 11:51:31 INFO Utils: /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/fetchFileTemp89009104113542187.tmp has been previously copied to /tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.apache.commons_commons-pool2-2.11.1.jar
25/05/14 11:51:31 INFO Executor: Adding file:/tmp/spark-0c8a5c5d-829b-454b-9546-f7ec7a6eef7b/userFiles-b62570cf-ac03-4ca9-8a07-eb552b1d11ee/org.apache.commons_commons-pool2-2.11.1.jar to class loader default
25/05/14 11:51:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42761.
25/05/14 11:51:31 INFO NettyBlockTransferService: Server created on b855e321a1ed:42761
25/05/14 11:51:31 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/05/14 11:51:31 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, b855e321a1ed, 42761, None)
25/05/14 11:51:31 INFO BlockManagerMasterEndpoint: Registering block manager b855e321a1ed:42761 with 434.4 MiB RAM, BlockManagerId(driver, b855e321a1ed, 42761, None)
25/05/14 11:51:31 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, b855e321a1ed, 42761, None)
25/05/14 11:51:31 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, b855e321a1ed, 42761, None)
25/05/14 11:51:32 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
25/05/14 11:51:32 INFO SharedState: Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
25/05/14 11:51:38 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
25/05/14 11:51:38 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-80240573-eac1-40b6-baf6-3c7b1fa2ae02. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.
25/05/14 11:51:38 INFO ResolveWriteToStream: Checkpoint root file:///tmp/temporary-80240573-eac1-40b6-baf6-3c7b1fa2ae02 resolved to file:/tmp/temporary-80240573-eac1-40b6-baf6-3c7b1fa2ae02.
25/05/14 11:51:38 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
25/05/14 11:51:39 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-80240573-eac1-40b6-baf6-3c7b1fa2ae02/metadata using temp file file:/tmp/temporary-80240573-eac1-40b6-baf6-3c7b1fa2ae02/.metadata.002f54da-c21d-45f4-8779-50927b0f9e9e.tmp
25/05/14 11:51:39 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-80240573-eac1-40b6-baf6-3c7b1fa2ae02/.metadata.002f54da-c21d-45f4-8779-50927b0f9e9e.tmp to file:/tmp/temporary-80240573-eac1-40b6-baf6-3c7b1fa2ae02/metadata
25/05/14 11:51:39 INFO MicroBatchExecution: Starting [id = 9289da71-5c12-4da8-9cd2-13224c5fe3ea, runId = d0a0d80e-f083-461d-9d99-79bd283d6ace]. Use file:/tmp/temporary-80240573-eac1-40b6-baf6-3c7b1fa2ae02 to store the query checkpoint.
25/05/14 11:51:40 INFO MicroBatchExecution: Reading table [org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaTable@3d26be8d] from DataSourceV2 named 'kafka' [org.apache.spark.sql.kafka010.KafkaSourceProvider@3c1e705c]
25/05/14 11:51:40 INFO OffsetSeqLog: BatchIds found from listing: 
25/05/14 11:51:40 INFO OffsetSeqLog: BatchIds found from listing: 
25/05/14 11:51:40 INFO MicroBatchExecution: Starting new streaming query.
25/05/14 11:51:40 INFO MicroBatchExecution: Stream started from {}
25/05/14 11:51:41 INFO AdminClientConfig: AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [kafka:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

25/05/14 11:51:42 WARN AdminClientConfig: These configurations '[key.deserializer, value.deserializer, enable.auto.commit, max.poll.records, auto.offset.reset]' were supplied but are not used yet.
25/05/14 11:51:42 INFO AppInfoParser: Kafka version: 3.4.1
25/05/14 11:51:42 INFO AppInfoParser: Kafka commitId: 8a516edc2755df89
25/05/14 11:51:42 INFO AppInfoParser: Kafka startTimeMs: 1747223502098
25/05/14 11:51:43 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-80240573-eac1-40b6-baf6-3c7b1fa2ae02/sources/0/0 using temp file file:/tmp/temporary-80240573-eac1-40b6-baf6-3c7b1fa2ae02/sources/0/.0.65febb4b-dff6-4c3c-be8d-46df258cdbc8.tmp
25/05/14 11:51:43 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-80240573-eac1-40b6-baf6-3c7b1fa2ae02/sources/0/.0.65febb4b-dff6-4c3c-be8d-46df258cdbc8.tmp to file:/tmp/temporary-80240573-eac1-40b6-baf6-3c7b1fa2ae02/sources/0/0
25/05/14 11:51:43 INFO KafkaMicroBatchStream: Initial offsets: {"new-scans":{"0":0}}
25/05/14 11:51:43 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-80240573-eac1-40b6-baf6-3c7b1fa2ae02/offsets/0 using temp file file:/tmp/temporary-80240573-eac1-40b6-baf6-3c7b1fa2ae02/offsets/.0.7f82e1d3-491b-4ee8-9664-ad73150472bb.tmp
25/05/14 11:51:44 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-80240573-eac1-40b6-baf6-3c7b1fa2ae02/offsets/.0.7f82e1d3-491b-4ee8-9664-ad73150472bb.tmp to file:/tmp/temporary-80240573-eac1-40b6-baf6-3c7b1fa2ae02/offsets/0
25/05/14 11:51:44 INFO MicroBatchExecution: Committed offsets for batch 0. Metadata OffsetSeqMetadata(0,1747223503866,Map(spark.sql.streaming.stateStore.providerClass -> org.apache.spark.sql.execution.streaming.state.HDFSBackedStateStoreProvider, spark.sql.streaming.join.stateFormatVersion -> 2, spark.sql.streaming.stateStore.compression.codec -> lz4, spark.sql.optimizer.pruneFiltersCanPruneStreamingSubplan -> false, spark.sql.streaming.stateStore.rocksdb.formatVersion -> 5, spark.sql.streaming.statefulOperator.useStrictDistribution -> true, spark.sql.streaming.flatMapGroupsWithState.stateFormatVersion -> 2, spark.sql.streaming.multipleWatermarkPolicy -> min, spark.sql.streaming.aggregation.stateFormatVersion -> 2, spark.sql.shuffle.partitions -> 200))
25/05/14 11:51:46 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/05/14 11:51:46 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/05/14 11:51:46 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/05/14 11:51:46 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/05/14 11:51:47 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/05/14 11:51:47 INFO KafkaOffsetReaderAdmin: Partitions added: Map()
25/05/14 11:51:48 INFO CodeGenerator: Code generated in 1022.875137 ms
25/05/14 11:51:49 INFO WriteToDataSourceV2Exec: Start processing data source write support: MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]]. The input RDD has 1 partitions.
25/05/14 11:51:49 INFO SparkContext: Starting job: start at <unknown>:0
25/05/14 11:51:49 INFO DAGScheduler: Got job 0 (start at <unknown>:0) with 1 output partitions
25/05/14 11:51:49 INFO DAGScheduler: Final stage: ResultStage 0 (start at <unknown>:0)
25/05/14 11:51:49 INFO DAGScheduler: Parents of final stage: List()
25/05/14 11:51:49 INFO DAGScheduler: Missing parents: List()
25/05/14 11:51:49 INFO DAGScheduler: Submitting ResultStage 0 (ParallelCollectionRDD[4] at start at <unknown>:0), which has no missing parents
25/05/14 11:51:49 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 3.4 KiB, free 434.4 MiB)
25/05/14 11:51:49 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 2034.0 B, free 434.4 MiB)
25/05/14 11:51:49 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on b855e321a1ed:42761 (size: 2034.0 B, free: 434.4 MiB)
25/05/14 11:51:49 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
25/05/14 11:51:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (ParallelCollectionRDD[4] at start at <unknown>:0) (first 15 tasks are for partitions Vector(0))
25/05/14 11:51:49 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
25/05/14 11:51:50 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (b855e321a1ed, executor driver, partition 0, PROCESS_LOCAL, 11069 bytes) 
25/05/14 11:51:50 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
25/05/14 11:51:50 INFO DataWritingSparkTask: Writer for partition 0 is committing.
25/05/14 11:51:50 INFO DataWritingSparkTask: Committed partition 0 (task 0, attempt 0, stage 0.0)
25/05/14 11:51:50 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1252 bytes result sent to driver
25/05/14 11:51:50 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 825 ms on b855e321a1ed (executor driver) (1/1)
25/05/14 11:51:50 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
25/05/14 11:51:51 INFO DAGScheduler: ResultStage 0 (start at <unknown>:0) finished in 1.659 s
25/05/14 11:51:51 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
25/05/14 11:51:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
25/05/14 11:51:51 INFO DAGScheduler: Job 0 finished: start at <unknown>:0, took 1.616450 s
25/05/14 11:51:51 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]] is committing.
-------------------------------------------
Batch: 0
-------------------------------------------
+------+---+---------+----+
|scanId|uri|timestamp|mime|
+------+---+---------+----+
+------+---+---------+----+

25/05/14 11:51:52 INFO WriteToDataSourceV2Exec: Data source write support MicroBatchWrite[epoch: 0, writer: ConsoleWriter[numRows=20, truncate=true]] committed.
25/05/14 11:51:52 INFO CheckpointFileManager: Writing atomically to file:/tmp/temporary-80240573-eac1-40b6-baf6-3c7b1fa2ae02/commits/0 using temp file file:/tmp/temporary-80240573-eac1-40b6-baf6-3c7b1fa2ae02/commits/.0.811ec47f-36f9-47a7-8f62-86cd06ec8ffc.tmp
25/05/14 11:51:52 INFO CheckpointFileManager: Renamed temp file file:/tmp/temporary-80240573-eac1-40b6-baf6-3c7b1fa2ae02/commits/.0.811ec47f-36f9-47a7-8f62-86cd06ec8ffc.tmp to file:/tmp/temporary-80240573-eac1-40b6-baf6-3c7b1fa2ae02/commits/0
25/05/14 11:51:52 INFO MicroBatchExecution: Streaming query made progress: {
  "id" : "9289da71-5c12-4da8-9cd2-13224c5fe3ea",
  "runId" : "d0a0d80e-f083-461d-9d99-79bd283d6ace",
  "name" : null,
  "timestamp" : "2025-05-14T11:51:40.219Z",
  "batchId" : 0,
  "numInputRows" : 0,
  "inputRowsPerSecond" : 0.0,
  "processedRowsPerSecond" : 0.0,
  "durationMs" : {
    "addBatch" : 5481,
    "commitOffsets" : 193,
    "getBatch" : 60,
    "latestOffset" : 3597,
    "queryPlanning" : 2480,
    "triggerExecution" : 12032,
    "walCommit" : 143
  },
  "stateOperators" : [ ],
  "sources" : [ {
    "description" : "KafkaV2[Subscribe[new-scans]]",
    "startOffset" : null,
    "endOffset" : {
      "new-scans" : {
        "0" : 0
      }
    },
    "latestOffset" : {
      "new-scans" : {
        "0" : 0
      }
    },
    "numInputRows" : 0,
    "inputRowsPerSecond" : 0.0,
    "processedRowsPerSecond" : 0.0,
    "metrics" : {
      "avgOffsetsBehindLatest" : "0.0",
      "maxOffsetsBehindLatest" : "0",
      "minOffsetsBehindLatest" : "0"
    }
  } ],
  "sink" : {
    "description" : "org.apache.spark.sql.execution.streaming.ConsoleTable$@4a686d6a",
    "numOutputRows" : 0
  }
}
25/05/14 11:51:57 INFO BlockManagerInfo: Removed broadcast_0_piece0 on b855e321a1ed:42761 in memory (size: 2034.0 B, free: 434.4 MiB)
25/05/14 11:52:02 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/05/14 11:52:12 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/05/14 11:52:22 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/05/14 11:52:32 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/05/14 11:52:42 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/05/14 11:52:52 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/05/14 11:53:02 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/05/14 11:53:12 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/05/14 11:53:22 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/05/14 11:53:32 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/05/14 11:53:42 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/05/14 11:53:52 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/05/14 11:54:02 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/05/14 11:54:12 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/05/14 11:54:22 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/05/14 11:54:32 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/05/14 11:54:42 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/05/14 11:54:52 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.
25/05/14 11:55:02 INFO MicroBatchExecution: Streaming query has been idle and waiting for new data more than 10000 ms.


# JARs necessari per:
# - scrivere su MinIO tramite s3a:// (hadoop-aws + AWS SDK)
# - leggere da Kafka via Spark Structured Streaming

spark.jars.dir /opt/spark/jars
spark.jars /opt/spark/jars/*

spark.hadoop.fs.s3a.access.key=minio
spark.hadoop.fs.s3a.secret.key=minio123
spark.hadoop.fs.s3a.endpoint=http://minio:9000
spark.hadoop.fs.s3a.path.style.access=true
spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem


# Altre impostazioni Spark utili (facoltative ma consigliate)
# spark.sql.shuffle.partitions 4
# spark.executor.memory 1g
# spark.driver.memory 1g
